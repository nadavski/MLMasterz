############################ Importing Libraries ###########################import numpy as npimport matplotlib.pyplot as pltimport pandas as pd######################### Importing Dataset ################################dataset = pd.read_csv('Data.csv')################## Index Independant and dependant values ##################x = dataset.iloc[:, 1:-1].valuesy = dataset.iloc[:, -1].values############################### Missing data ############################################################# By the avarage ##############################from sklearn.impute import SimpleImputerimputer =  SimpleImputer(missing_values=np.nan, strategy='mean')imputer.fit(x[:, 1:3])x[:, 1:3] = imputer.transform(x[:, 1:3])### Check with #print(x)######################### Encoding categorical data ############################################# Encoding the Independant variable ####################from sklearn.compose import ColumnTransformerfrom sklearn.preprocessing import OneHotEncoderct = ColumnTransformer(transformers =[('encoder', OneHotEncoder(), [0])], remainder='passthrough')x = np.array(ct.fit_transform(x))######################### Encoding categorical data ############################################## Encoding the Dependant variable #####################from sklearn.preprocessing import LabelEncoderle = LabelEncoder()y = le.fit_transform(y)############ Splitting the dataset into Training set and Test set ###########from sklearn.model_selection import train_test_splitx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)#print(x_train)#print(x_test)#print(y_train)#print(y_test)############################# Feature Scaling #############################from sklearn.preprocessing import StandardScalersc = StandardScaler()x_train[:, 3:] = sc.fit_transform(x_train[:, 3:])x_test[:, 3:] = sc.transform(x_test[:, 3:])#print(x_train)#print(x_test)